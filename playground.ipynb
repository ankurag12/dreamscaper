{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70842b9-7ba9-4a6b-8f89-a7acee584a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bc06d1-68bb-4ebc-a30c-18a43fc77997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_token():\n",
    "    with open(\".token.txt\", \"r\") as f:\n",
    "        hf_token = f.read()\n",
    "    return hf_token\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f2a8fb-f0d1-44d9-9cb3-f5a21d676130",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = read_token()\n",
    "client = InferenceClient(\"black-forest-labs/FLUX.1-dev\", token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecb487f1-40c6-42eb-a215-f4e54bc1524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output is a PIL.Image object\n",
    "image = client.text_to_image(\"Astronaut riding a horse on moon\")\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d718baee-dc18-4fc2-8570-e8dd6e6b6145",
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "504 Server Error: Gateway Timeout for url: https://api-inference.huggingface.co/models/timbrooks/instruct-pix2pix (Request ID: zzppyQoI1GeM5GpzaS8yG)\n\nModel timbrooks/instruct-pix2pix time out",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace/ankurag12/dreamscaper/.env/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/workspace/ankurag12/dreamscaper/.env/lib/python3.13/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 504 Server Error: Gateway Timeout for url: https://api-inference.huggingface.co/models/timbrooks/instruct-pix2pix",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# output is a PIL.Image object\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcruise.jpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMake the person run on a track\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimbrooks/instruct-pix2pix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m image\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/workspace/ankurag12/dreamscaper/.env/lib/python3.13/site-packages/huggingface_hub/inference/_client.py:1291\u001b[0m, in \u001b[0;36mInferenceClient.image_to_image\u001b[0;34m(self, image, prompt, negative_prompt, num_inference_steps, guidance_scale, model, target_size, **kwargs)\u001b[0m\n\u001b[1;32m   1282\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: negative_prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1289\u001b[0m }\n\u001b[1;32m   1290\u001b[0m payload \u001b[38;5;241m=\u001b[39m _prepare_payload(image, parameters\u001b[38;5;241m=\u001b[39mparameters, expect_binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1291\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage-to-image\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bytes_to_image(response)\n",
      "File \u001b[0;32m~/workspace/ankurag12/dreamscaper/.env/lib/python3.13/site-packages/huggingface_hub/inference/_client.py:306\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/workspace/ankurag12/dreamscaper/.env/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:477\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 477\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 504 Server Error: Gateway Timeout for url: https://api-inference.huggingface.co/models/timbrooks/instruct-pix2pix (Request ID: zzppyQoI1GeM5GpzaS8yG)\n\nModel timbrooks/instruct-pix2pix time out"
     ]
    }
   ],
   "source": [
    "# output is a PIL.Image object\n",
    "image = client.image_to_image(image=\"cruise.jpeg\", prompt=\"Make the person run on a track\", model=\"timbrooks/instruct-pix2pix\")\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3dff40-243c-48e5-bbc1-badd2febf91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import requests\n",
    "from diffusers import StableDiffusionInstructPix2PixPipeline, EulerAncestralDiscreteScheduler\n",
    "\n",
    "model_id = \"timbrooks/instruct-pix2pix\"\n",
    "pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(model_id, torch_dtype=torch.float16, safety_checker=None)\n",
    "pipe.to(\"cuda\")\n",
    "pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/timothybrooks/instruct-pix2pix/main/imgs/example.jpg\"\n",
    "def download_image(url):\n",
    "    image = PIL.Image.open(requests.get(url, stream=True).raw)\n",
    "    image = PIL.ImageOps.exif_transpose(image)\n",
    "    image = image.convert(\"RGB\")\n",
    "    return image\n",
    "image = download_image(url)\n",
    "\n",
    "prompt = \"turn him into cyborg\"\n",
    "images = pipe(prompt, image=image, num_inference_steps=10, image_guidance_scale=1).images\n",
    "images[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24f2632-a1fb-40a3-9672-753e31694348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e34789b-22bf-4677-b3ad-38f6c12e4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_access_key():\n",
    "    with open(\".pico_access_key.txt\", \"r\") as f:\n",
    "        access_key = f.read()\n",
    "    return access_key\n",
    "pico_access_key = read_access_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6e232e-aa90-41a8-9f12-75f5d8cc9349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-20 23:21:54.880386] Detected picovoice\n",
      "[2025-01-20 23:22:03.932136] Detected bumblebee\n",
      "Stopping ...\n"
     ]
    }
   ],
   "source": [
    "import pvporcupine\n",
    "from pvrecorder import PvRecorder\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "keywords=['picovoice', 'bumblebee']\n",
    "\n",
    "porcupine = pvporcupine.create(\n",
    "    access_key=pico_access_key,\n",
    "    keywords=keywords\n",
    ")\n",
    "\n",
    "recorder = PvRecorder(\n",
    "    frame_length=porcupine.frame_length)\n",
    "\n",
    "recorder.start()\n",
    "\n",
    "\n",
    "def get_next_audio_frame():\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        pcm = recorder.read()\n",
    "        keyword_index = porcupine.process(pcm)\n",
    "        \n",
    "        if keyword_index >= 0:\n",
    "            print(f\"[{datetime.now()}] Detected {keywords[keyword_index]}\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print('Stopping ...')\n",
    "finally:\n",
    "    recorder.delete()\n",
    "    porcupine.delete()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672207e3-c522-4a01-a6fc-295f7733aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pvcheetah\n",
    "\n",
    "cheetah = pvcheetah.create(access_key=pico_access_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
